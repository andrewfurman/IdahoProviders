Below is a **drop-in replacement** for `models/work_queue.py`, plus the matching DDL you’ll want to add (or generate with Alembic) so the single **`work_queue_items`** table can now cover **both** kinds of recommendations — *field updates* and *duplicate merges*.

---

### 1  Updated SQLAlchemy model  

```python
# models/work_queue.py
from datetime import datetime
from sqlalchemy.dialects.postgresql import ARRAY          # ← NEW
from .db import db

class WorkQueueItem(db.Model):
    __tablename__ = "work_queue_items"

    # ── core identity ──────────────────────────────────────────────────────
    queue_id            = db.Column(db.Integer, primary_key=True)
    provider_id         = db.Column(db.Integer,
                          db.ForeignKey("individual_providers.provider_id",
                                        ondelete="CASCADE"),
                          nullable=False)

    # ── problem description ───────────────────────────────────────────────
    issue_type          = db.Column(db.String(40), nullable=False)   # e.g. duplicate, missing_data
    description         = db.Column(db.Text,        nullable=False)

    # ── **structured recommendation** ─────────────────────────────────────
    action_type         = db.Column(db.String(20), nullable=False,
                          default="update_field")   # 'update_field' | 'merge_duplicates'
    field_name          = db.Column(db.Text)                     # only for update_field
    new_value           = db.Column(db.Text)                     # only for update_field
    duplicate_ids       = db.Column(ARRAY(db.Integer))           # only for merge_duplicates

    # free-text summary users can edit in UI
    recommended_action  = db.Column(db.Text)

    # ── workflow / assignment ─────────────────────────────────────────────
    status              = db.Column(db.String(20), default="open", nullable=False)
    assigned_user_id    = db.Column(db.Integer, db.ForeignKey("users.id", ondelete="SET NULL"))
    created_by_user_id  = db.Column(db.Integer, db.ForeignKey("users.id", ondelete="SET NULL"))

    created_at          = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)
    updated_at          = db.Column(db.DateTime, nullable=False, default=datetime.utcnow,
                                    onupdate=datetime.utcnow)
    resolved_at         = db.Column(db.DateTime)

    # ── relationships ─────────────────────────────────────────────────────
    provider            = db.relationship("IndividualProvider")
    assigned_user       = db.relationship("User", foreign_keys=[assigned_user_id])
    created_by_user     = db.relationship("User", foreign_keys=[created_by_user_id])

    # ── convenience helpers (optional) ────────────────────────────────────
    def is_duplicate_merge(self) -> bool:
        return self.action_type == "merge_duplicates"
```

**Why these columns?**

| Column              | Purpose | Example value |
|---------------------|---------|---------------|
| `action_type`       | Distinguishes **update vs merge** logic so your code can branch cleanly | `"merge_duplicates"` |
| `field_name`        | Which attribute will change when `action_type='update_field'` | `"npi"` |
| `new_value`         | Proposed value for that field | `"1234567890"` |
| `duplicate_ids`     | *Integer array* of every provider that should be merged (including `provider_id` itself); Postgres makes this painless | `{1, 2, 3}` |

> Keeping everything in one table avoids new joins and lets you render any work-item with the same UI, while still giving you enough structure to write automated “Apply fix” helpers later.

---

### 2  SQL / migration snippet

If you’re managing migrations by hand, extend the `CREATE TABLE` block in **`create_tables.py`** (or write an Alembic upgrade) like so ⬇︎

```sql
ALTER TABLE work_queue_items
    ADD COLUMN action_type      VARCHAR(20) NOT NULL DEFAULT 'update_field',
    ADD COLUMN field_name       TEXT,
    ADD COLUMN new_value        TEXT,
    ADD COLUMN duplicate_ids    INTEGER[];  -- Postgres array of provider_ids
```

*(Existing rows default to a harmless `"update_field"` action; you can back-fill later if needed.)*

---

### 3  Using the new fields

| Scenario | Minimal payload you’d insert |
|----------|-----------------------------|
| **Fix blank NPI** | `issue_type='missing_data', action_type='update_field', field_name='npi', new_value='1234567890'` |
| **Merge dupes (1,2,3)** | `issue_type='duplicate', action_type='merge_duplicates', duplicate_ids=[1,2,3]` |

Your current routes/forms already capture `recommended_action`.  
To capture the structured pieces:

1. **Form inputs** – add hidden fields or new inputs for `action_type`, `field_name`, `new_value`, etc.  
2. **Route update** – pull those with `request.form.get("field_name")`, assign to the new model attributes, and commit.

---

### 4  Next steps checklist

- [ ] Add the `sqlalchemy.dialects.postgresql.ARRAY` import (model above has it).  
- [ ] Run the `ALTER TABLE` (or an Alembic migration) against every environment.  
- [ ] Adjust `WorkQueueItem` creation logic to populate the new columns.  
- [ ] Extend the UI later to display “Proposed change ➜ *NPI → 1234567890*” or “Merge 3 records”.  
- [ ] Optionally add a **GIN index** on `duplicate_ids` if you’ll query by contained provider_id (`duplicate_ids @> ARRAY[?]`).

That’s it—your single-table work-queue model is now ready for both targeted field fixes **and** full duplicate-merge recommendations.